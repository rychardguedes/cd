{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Métodos e Métricas de Avaliação"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "**Leia o dataset iris e armazene em uma variável chamada ds. Os próximos exercícios serão utilizando esses dataset.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Sepal.Length</th>\n",
       "      <th>Sepal.Width</th>\n",
       "      <th>Petal.Length</th>\n",
       "      <th>Petal.Width</th>\n",
       "      <th>Species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  Sepal.Length  Sepal.Width  Petal.Length  Petal.Width Species\n",
       "0           1           5.1          3.5           1.4          0.2  setosa\n",
       "1           2           4.9          3.0           1.4          0.2  setosa\n",
       "2           3           4.7          3.2           1.3          0.2  setosa\n",
       "3           4           4.6          3.1           1.5          0.2  setosa\n",
       "4           5           5.0          3.6           1.4          0.2  setosa"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "ds = pd.read_csv('datasets/iris.csv')\n",
    "ds.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "**Considerando que o dataset seja avaliado utilizando K-Fold Cross Validation com K = 2, quantos dados existirão em cada fold? Existe algum nome específico ao fazer uso de K = 2?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150, 6)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Considerando que existem 150 instâncias no conjunto de dados, ao fazer um K-Fold Cross Validation com 2 folds, teremos 75 instâncias em cada fold. Isso lembra uma técnica conhecida como Hold Out, com a diferença que no Hold Out a proporção de treino e teste pode ser diferente (aqui 50% é treino e 50% é teste) e e que no Cross Validation, como o próprio nome salienta, ora uma parte será usada para treino, ora para teste."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "**Considerando que o dataset seja avaliado utilizando K-Fold Cross Validation com K = 150, quantos dados existirão em cada fold? Existe algum nome específico ao fazer uso de K = 150?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    " Existirá 1 instância em cada fold. Nesses casos, pode ser chamado também de Leave One Out."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "**Em sua visão, considerando que todos os dados disponíveis para uso são o que estão em ds, qual dos K (2 ou 150) deve ser utilizado? Por que?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    " Como existem poucas instâncias, faz sentido utilizar K = 150, já que demandará de pouco poder computacional."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "**No conjunto de dados apresentado, existiria algum problema em determinar o folds de forma sequencial? Por que?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['setosa'], dtype=object)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds.iloc[:50, -1].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['versicolor'], dtype=object)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds.iloc[51:100, -1].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['virginica'], dtype=object)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds.iloc[-50:, -1].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Como os dados estão dispostos na base de forma que as primeiras 50 linhas pertençam apenas à classe setosa, as 50 próximas à classe versicolor e as 50 últimas à classe virgínica, não é interessante que os folds sejam separados de forma sequencial, já que assim as amostras que estariam sendo usadas para teste e treino não estariam fazendo ujma boa representação da base completa/realidade."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "**Qual a vantagem de separar os dados de forma estratiticada?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    " A principal vantagem é manter uma aproximação da base original no que diz respeito à proporção de classes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "**Utilizando a biblioteca sklearn, separe os dados de teste e treino, com 75% para treino, de forma sequencial. Observe o que acontece com as classes. Essa é a melhor forma de separar? Caso contrário, o que pode ser feito?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split \n",
    "\n",
    "ds_treino, ds_teste = train_test_split(ds, train_size = 0.75, test_size = 0.25, shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "setosa        50\n",
       "versicolor    50\n",
       "virginica     12\n",
       "Name: Species, dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds_treino.Species.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "virginica    38\n",
       "Name: Species, dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds_teste.Species.value_counts() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Essa não é uma boa forma de separar por não manter uma proporção de classes condizente com a realidade/base original. O que pode ser feito é um embaralhamento das instâncias, determinando que parâmetro shuffle receba o True."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "**Separe o conjunto de dados em treino e teste, utilizando K-Fold Cross Validation, com K = 10. Calcule a média e mediana da variável Sepal.Length de cada conjunto (treino e teste) em cada iteração.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Média treino: 5.84\n",
      "Média teste: 6.0\n",
      "Mediana treino: 6.0\n",
      "Mediana teste: 6.0\n",
      "====================\n",
      "Média treino: 5.88\n",
      "Média teste: 5.0\n",
      "Mediana treino: 6.0\n",
      "Mediana teste: 6.0\n",
      "====================\n",
      "Média treino: 5.85\n",
      "Média teste: 6.0\n",
      "Mediana treino: 6.0\n",
      "Mediana teste: 6.0\n",
      "====================\n",
      "Média treino: 5.82\n",
      "Média teste: 6.0\n",
      "Mediana treino: 6.0\n",
      "Mediana teste: 6.0\n",
      "====================\n",
      "Média treino: 5.84\n",
      "Média teste: 6.0\n",
      "Mediana treino: 6.0\n",
      "Mediana teste: 6.0\n",
      "====================\n",
      "Média treino: 5.84\n",
      "Média teste: 6.0\n",
      "Mediana treino: 6.0\n",
      "Mediana teste: 6.0\n",
      "====================\n",
      "Média treino: 5.86\n",
      "Média teste: 6.0\n",
      "Mediana treino: 6.0\n",
      "Mediana teste: 5.0\n",
      "====================\n",
      "Média treino: 5.79\n",
      "Média teste: 6.0\n",
      "Mediana treino: 6.0\n",
      "Mediana teste: 6.0\n",
      "====================\n",
      "Média treino: 5.86\n",
      "Média teste: 6.0\n",
      "Mediana treino: 6.0\n",
      "Mediana teste: 6.0\n",
      "====================\n",
      "Média treino: 5.85\n",
      "Média teste: 6.0\n",
      "Mediana treino: 6.0\n",
      "Mediana teste: 6.0\n",
      "====================\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "import numpy as np\n",
    "\n",
    "kf = KFold(n_splits = 10, shuffle = True)\n",
    "\n",
    "for i_treino, i_teste in kf.split(ds):\n",
    "    \n",
    "    ds_treino = ds.iloc[i_treino, :].loc[:, 'Sepal.Length']\n",
    "    ds_teste = ds.iloc[i_teste, :].loc[:, 'Sepal.Length']\n",
    "    \n",
    "    print('Média treino:', round(np.mean(ds_treino), 2))\n",
    "    print('Média teste:', round(np.mean(ds_teste)))\n",
    "    \n",
    "    print('Mediana treino:', round(np.median(ds_treino)))\n",
    "    print('Mediana teste:', round(np.median(ds_teste)))\n",
    "    \n",
    "    print('====================')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "**Da mesma forma que a questão anterior, separe o conjunto de dados em treino e teste, utilizando K-Fold Cross Validation, com K = 10. Padronize os dados da variável Sepal.Length para que fiquem entre 0 e 1. Dica: é importante tomar cuidado com data leak.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min/Max do treino: 0.0 1.0\n",
      "Min/Max do teste: 0.0277777777777779 0.8055555555555556\n",
      "====================\n",
      "Min/Max do treino: 0.0 1.0\n",
      "Min/Max do teste: 0.11111111111111116 0.7222222222222223\n",
      "====================\n",
      "Min/Max do treino: 0.0 1.0\n",
      "Min/Max do teste: 0.16666666666666674 0.9444444444444442\n",
      "====================\n",
      "Min/Max do treino: 0.0 1.0\n",
      "Min/Max do teste: 0.11111111111111116 0.7222222222222223\n",
      "====================\n",
      "Min/Max do treino: 0.0 1.0\n",
      "Min/Max do teste: 0.13888888888888884 0.8611111111111112\n",
      "====================\n",
      "Min/Max do treino: 0.0 1.0\n",
      "Min/Max do teste: 0.08333333333333326 0.9444444444444442\n",
      "====================\n",
      "Min/Max do treino: 0.0 1.0\n",
      "Min/Max do teste: 0.08333333333333326 0.9444444444444442\n",
      "====================\n",
      "Min/Max do treino: 0.0 1.0\n",
      "Min/Max do teste: -0.028571428571428692 0.657142857142857\n",
      "====================\n",
      "Min/Max do treino: 0.0 0.9999999999999998\n",
      "Min/Max do teste: 0.02941176470588247 1.0588235294117647\n",
      "====================\n",
      "Min/Max do treino: 0.0 1.0\n",
      "Min/Max do teste: 0.13888888888888884 0.9444444444444442\n",
      "====================\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler(copy = False)\n",
    "\n",
    "for i_treino, i_teste in kf.split(ds):\n",
    "    \n",
    "    ds_treino = ds.iloc[i_treino, :].loc[:, 'Sepal.Length']\n",
    "    ds_teste = ds.iloc[i_teste, :].loc[:, 'Sepal.Length']\n",
    "    \n",
    "    # MinMaxScaler pede que os dados estejam em um array de 2 dimensões\n",
    "    ds_treino = ds_treino.values.reshape(-1, 1)\n",
    "    ds_teste = ds_teste.values.reshape(-1, 1)\n",
    "    \n",
    "    scaler.fit_transform(ds_treino)\n",
    "    scaler.transform(ds_teste)\n",
    "    \n",
    "    print('Min/Max do treino:', ds_treino.min(), ds_treino.max())\n",
    "    print('Min/Max do teste:', ds_teste.min(), ds_teste.max())\n",
    "    \n",
    "    print('====================')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "**Leia o arquivo *saidas.csv*. Calcule a acurácia, precisão e revocação de y1_pred e y1_real.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acurácia: 0.865\n",
      "Precisão: 0.8475247524752475\n",
      "Revocação: 0.8806584362139918\n"
     ]
    }
   ],
   "source": [
    "saidas = pd.read_csv('datasets/saidas.csv')\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "\n",
    "print('Acurácia:', accuracy_score(saidas.y1_real, saidas.y1_pred))\n",
    "print('Precisão:', precision_score(saidas.y1_real, saidas.y1_pred))\n",
    "print('Revocação:', recall_score(saidas.y1_real, saidas.y1_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "**Leia o arquivo saidas.csv. Calcule a acurácia, precisão e revocação de y2_pred1 e y2_real. Tenha atenção especial para as classes desse problema. É possível verificar algum problema? O que pode ser feito?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acurácia: 0.944\n",
      "Precisão: 0.944\n",
      "Revocação: 1.0\n"
     ]
    }
   ],
   "source": [
    "print('Acurácia:', accuracy_score(saidas.y2_real, saidas.y2_pred1))\n",
    "print('Precisão:', precision_score(saidas.y2_real, saidas.y2_pred1))\n",
    "print('Revocação:', recall_score(saidas.y2_real, saidas.y2_pred1)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    944\n",
       "0     56\n",
       "Name: y2_real, dtype: int64"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "saidas.y2_real.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    1000\n",
       "Name: y2_pred1, dtype: int64"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "saidas.y2_pred1.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As classes estão extremamente desbalanceadas, o que faz com que métricas de acurácia, precisão e revocação não sejam boas para concluir se um modelo está fazendo boas predições ou não. Nesse caso, o modelo simplesmente previu que todas as classes eram pertencentes à classe majoritária e ainda assim obveteve acurácia de 94%. Outras métricas de avaliação devem ser usadas nesses casos, ou ainda fazer um balanceamento por meio de undersampling ou oversampling."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Leia o arquivo saidas.csv. Observe as saídas y2_real, y2_pred1 e y2_pred2. Qual a melhor métrica para comparar os modelos que geraram essa saída?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Boas métricas para casos desbalanceados são Area Under the ROC Curve (AUC) ou Gini."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC Modelo 1: 0.5\n",
      "Gini Modelo 1: 0.0\n",
      "\n",
      "AUC Modelo 2: 0.9533898305084746\n",
      "Gini Modelo 2: 0.9067796610169492\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "\n",
    "print('AUC Modelo 1:', roc_auc_score(saidas.y2_real, saidas.y2_pred1))\n",
    "print('Gini Modelo 1:', (2*roc_auc_score(saidas.y2_real, saidas.y2_pred1) - 1))\n",
    "print()\n",
    "print('AUC Modelo 2:', roc_auc_score(saidas.y2_real, saidas.y2_pred2))\n",
    "print('Gini Modelo 2:', (2*roc_auc_score(saidas.y2_real, saidas.y2_pred2) - 1))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
